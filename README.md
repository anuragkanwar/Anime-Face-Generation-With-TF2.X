# Anime-Face-Generation-With-TF2.X

Generating anime faces using a Deep Convolutional Generative Adversarial Network (DCGAN).

### Tech Used
![TensorFlow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=for-the-badge&logo=TensorFlow&logoColor=white) ![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white) ![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white) ![Keras](https://img.shields.io/badge/Keras-%23D00000.svg?style=for-the-badge&logo=Keras&logoColor=white) ![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)

## Demo

![appscreenshot](https://github.com/anuragkanwar/Anime-Face-Generation-With-TF2.X/blob/main/Assests/image_at_epoch_0016.png)


## Objectives

- The objective of the project is to generate images of Anime faces using a Deep Convolutional GAN.
- The DCGAN has two networks, the 'generator' and the 'discriminator'.
- The generator takes in a random vector which then uses transposed convolutions to generate an image out of it.
- The discriminator is a Convolutional network which then classifies whether an image is real or fake. It takes in samples of images from the dataset and also images generated by the generator.
- Both networks try to improve each other's performance through backpropagation.

## Architecture
The architecture is inspired by the original DCGAN paper. However 'one-sided label smoothing' has been added to prevent the discriminator from overpowering the generator. The weights for the generator and discriminator can be found [here](https://arxiv.org/pdf/1511.06434v2.pdf)
<p align="center">
  <img alt="Balasana" src="https://github.com/anuragkanwar/Anime-Face-Generation-With-TF2.X/blob/main/Assests/Capstone%20Architecture%402x%20(1).png" width="45%">
</p>

### Generator
he generator takes in a 64 dimensional noise vector sampled from a normal distribution of zero mean and unit variance N(0,1). It is then followed by a Dense layer of 4x4x512 units and reshaped to (4,4,512).
Then a few transposed convolutional layers are followed which then results in an image of size (64,64,3) with pixel values of the range [-1,1] due to a tanh activation.

### Discriminator
The discriminator is similar to a image classification CNN which takes in an image and outputs the probability of it being real.
## Results
<p align="center">
  <img alt="Balasana" src="https://github.com/anuragkanwar/Anime-Face-Generation-With-TF2.X/blob/main/Assests/animeGAN.gif" width="25%" >
</p>


# Requirements ‚úÖ
- ###### python 3.9.0+
- ###### Tensorflow 2.x.x

Note: for running on a GPU instance you will require to download the respective CUDA and cuDNN (if the GPU present is CUDA compatible) versions to work with tensorflow.
CUDA compatibility can be checked [here](https://developer.nvidia.com/cuda-gpus)

# Instructions üìù
- Clone the repository
- Download the dataset from [Kaggle](https://www.kaggle.com/soumikrakshit/anime-faces) into the same directory as the cloned repo (only required if training from scratch)
- Download the trained weights from [here](https://drive.google.com/drive/folders/1-9nBA6tI3Gp_hSW7CiEAcmrWvbvY11YF?usp=sharing) for testing
- Run `jupyter notebook`
- Run the notebook `Anime_face_generation.ipynb`

Note: It is advised to train the model on a GPU. Training on a CPU can be time consuming.

# Acknowledgements
- The original DCGAN research paper https://arxiv.org/abs/1511.06434
- Tip for label smoothing https://towardsdatascience.com/gan-ways-to-improve-gan-performance-acf37f9f59b
- Google Developers tutorial on generative adversarial networks https://developers.google.com/machine-learning/gan

# Libraries used
- [NumPy](https://numpy.org/)
- [Tensorflow](https://www.tensorflow.org/)
- [Keras](https://keras.io/)
- [matplotlib](https://matplotlib.org/api/pyplot_api.html)
